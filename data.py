# -*- coding: utf-8 -*-
"""data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kjy0kzD5EzGB7nZBc_GIMkxy2aRgCd2L
"""

import os
from os import listdir
import json
import torch
import scipy.misc
import numpy 
import glob

import torch.nn as nn
import torchvision.transforms as transforms

from torch.utils.data import Dataset
from PIL import Image

MEAN = [0.485, 0.456, 0.406]
STD = [0.229, 0.224, 0.225]

class DATA(Dataset):
    def __init__(self, args, mode ='train'):

        ''' set up basic parameters for dataset '''
        self.mode = mode
        self.data_dir = args.data_dir
        self.img_dir = os.path.join(self.data_dir, mode + '/img')
        self.img_dir_label = os.path.join(self.data_dir, mode +'/seg')

        ''' read the data list '''
         # Enter Directory of all images 
        #data_path = os.path.join(img_dir,'*g')
        #files = glob.glob(data_path)
        #files.sort() 
       # data_list = []
        #print('test')
       # for f1 in listdir(self.img_dir):
           # print('test')
            #img = cv2.imread(f1)
       # data.append(img)
            #data_list.append(f1)
            #data_list.append(f1)
        json_path = os.path.join(mode + '.json')
        with open(json_path, 'r') as f:
            self.data = json.load(f)
      #  array = np.array(data_list)
      #  array = array.reshape(-1,2)
      #  self.data = array

        ''' set up image path '''
        for d in self.data:
            d[0] = os.path.join(self.img_dir, d[0])
            #print('d[0]: ' + d[0])
            d[1] = os.path.join(self.img_dir_label, d[1])
            #print('d[1]: ' +d[1])
        ''' set up image trainsform '''
        if self.mode == 'train':
            self.transform = transforms.Compose([
                              # transforms.RandomHorizontalFlip(0.5),
                               transforms.ToTensor(), # (H,W,C)->(C,H,W), [0,255]->[0, 1.0] RGB->RGB
                               transforms.Normalize(MEAN, STD)
                               ])

        elif self.mode == 'val' or self.mode == 'test':
            self.transform = transforms.Compose([
                               transforms.ToTensor(), # (H,W,C)->(C,H,W), [0,255]->[0, 1.0] RGB->RGB
                               transforms.Normalize(MEAN, STD)
                               ])


    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):

        ''' get data '''
        img_path, cls = self.data[idx]
     
        ''' read image '''
        img = Image.open(img_path).convert('RGB')
        cls = Image.open(cls).convert('L')  #segmenation map 
        cls = numpy.array(cls)
        cls = torch.from_numpy(cls)
        cls = cls.long()
       
        return self.transform(img), cls
